{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the \"greenCall\" python package\n",
    "\n",
    "At this point in time, the greenCall python package requires a series of function calls \n",
    "to make our way through the data pipeline. The pipeline consists of the following:\n",
    "\n",
    "1. Read the csv file formatted as (unique id, query term)\n",
    "2. Request information from the Search API \n",
    "3. Write results to disk in JSON format\n",
    "4. Bulk upload results to elasticsearch\n",
    "\n",
    "This notebook provides a concise example of how to work through the data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing secret keys \n",
    "from examples.secret import secret_key #, secret_cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Google Custom Search API id\n",
    "#CX = secret_cx\n",
    "\n",
    "# Secret Key required to access the API\n",
    "SECRET_KEY = secret_key\n",
    "\n",
    "# Maximum number of query items to request from API\n",
    "QUERY_LIMIT = 5\n",
    "\n",
    "# Maximum number or requests deferred\n",
    "MAX_RUN = 20\n",
    "\n",
    "# This many seconds will expire between requests sent\n",
    "RATE_LIMIT = 1\n",
    "\n",
    "# Path to original excel file, converted to CSV\n",
    "filepath = 'examples/finance_demo.csv'\n",
    "\n",
    "# Path to converted file to be used for API requests\n",
    "outpath = 'examples/ipython_demo.json'\n",
    "\n",
    "# results returned from the API via the networking engine\n",
    "resultspath = 'results.json'\n",
    "\n",
    "# Specify a document template for Elasticsearch\n",
    "esformat = {\n",
    "            \"_index\": \"ipythonsearch\",\n",
    "            \"_type\": \"website\",\n",
    "            \"_id\": None,\n",
    "            \"_source\": \"\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Start Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from greencall.utils.utilityBelt import enable_log\n",
    "\n",
    "# Log everything, always.\n",
    "enable_log('crawlah')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 (Reading the CSV file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from greencall.csvclean.inputCsv import tojson\n",
    "\n",
    "# Convert the input file from CSV to JSON\n",
    "tojson(filepath, outpath, QUERY_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 ( Request information from the Search API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from greencall.csvclean.clientConversion import runConversion\n",
    "#from examples.secret import secret_key\n",
    "\n",
    "# Use the API client to convert query terms into correct format\n",
    "# for API requests. Currently hard coded for Google Search API\n",
    "adict = runConversion(jsonpath=outpath,\n",
    "                      secretKey= secret_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 (Write results to disk in JSON format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twisted.internet import reactor\n",
    "from greencall.crawlah import getPages\n",
    "\n",
    "# Load the network engine which handles API requests (gas & brakes)\n",
    "gp = getPages(adict, MAX_RUN, RATE_LIMIT)\n",
    "\n",
    "# Start the networking engine\n",
    "\n",
    "gp.start()\n",
    "reactor.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 (Bulk upload into elasticsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from greencall.utils.google import GoogleParse\n",
    "from greencall.utils.loadelastic import load_elastic, read_json\n",
    "from greencall.csvclean.inputCsv import read_csv\n",
    "\n",
    "# set elastic search document id to 1 (assumes new index)\n",
    "gp = GoogleParse(es_id = 1)\n",
    "\n",
    "# params \n",
    "resultsdict = read_json(resultspath)\n",
    "accountdict = read_csv(filepath, QUERY_LIMIT)\n",
    "\n",
    "# need to hook up these params\n",
    "load_docs = gp.update_es_doc_id(resultsdict, accountdict, esformat)\n",
    "\n",
    "# bulk load elasticsearch\n",
    "load_elastic(load_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
