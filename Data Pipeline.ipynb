{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the \"greenCall\" python package\n",
    "\n",
    "At this point in time, the greenCall python package requires a series of function calls \n",
    "to make our way through the data pipeline. The pipeline consists of the following:\n",
    "\n",
    "1. Read the csv file formatted as (unique id, query term)\n",
    "2. Request information from the Search API \n",
    "3. Write results to disk in JSON format\n",
    "4. Bulk upload results to elasticsearch\n",
    "\n",
    "This notebook provides a concise example of how to work through the data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Maximum number of query items to request from API\n",
    "QUERY_LIMIT = 5\n",
    "\n",
    "# Maximum number or requests deferred\n",
    "MAX_RUN = 20\n",
    "\n",
    "# This many seconds will expire between requests sent\n",
    "RATE_LIMIT = 1\n",
    "\n",
    "# Path to original excel file, converted to CSV\n",
    "filepath = 'examples/finance_demo.csv'\n",
    "\n",
    "# Path to converted file to be used for API requests\n",
    "outpath = 'examples/ipython_demo.json'\n",
    "\n",
    "# results returned from the API via the networking engine\n",
    "resultspath = 'results.json'\n",
    "\n",
    "# Specify a document template for Elasticsearch\n",
    "esformat = {\n",
    "            \"_index\": \"ipythonsearch\",\n",
    "            \"_type\": \"website\",\n",
    "            \"_id\": None,\n",
    "            \"_source\": \"\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Start Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from greencall.utils.utilityBelt import enable_log\n",
    "\n",
    "# Log everything, always.\n",
    "enable_log('crawlah')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 (Reading the CSV file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from greencall.csvclean.inputCsv import tojson\n",
    "\n",
    "# Convert the input file from CSV to JSON\n",
    "tojson(filepath, outpath, QUERY_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 ( Request information from the Search API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from greencall.csvclean.clientConversion import runConversion\n",
    "from examples.secret import secret_key\n",
    "\n",
    "# Use the API client to convert query terms into correct format\n",
    "# for API requests. Currently hard coded for Google Search API\n",
    "adict = runConversion(jsonpath=outpath,\n",
    "                      secretKey= secret_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 (Write results to disk in JSON format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twisted.internet import reactor\n",
    "from greencall.crawlah import getPages\n",
    "\n",
    "# Load the network engine which handles API requests (gas & brakes)\n",
    "gp = getPages(adict, MAX_RUN, RATE_LIMIT)\n",
    "\n",
    "# Start the networking engine\n",
    "\n",
    "gp.start()\n",
    "reactor.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 (Bulk upload into elasticsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f840ee992e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# need to hook up these params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mload_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_es_doc_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultsdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccountdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mesformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# bulk load elasticsearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tbonza/code/greenCall/greencall/utils/google.pyc\u001b[0m in \u001b[0;36mupdate_es_doc_id\u001b[1;34m(self, resultsdict, accountdict, esformat)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;34m\"\"\" Updates the es doc id using a generator \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         docs = self.create_google_es_docs(resultsdict, accountdict,\n\u001b[1;32m--> 203\u001b[1;33m                                           esformat)\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[0mnum_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mitercount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mes_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tbonza/code/greenCall/greencall/utils/google.pyc\u001b[0m in \u001b[0;36mcreate_google_es_docs\u001b[1;34m(self, resultsdict, accountdict, esformat)\u001b[0m\n\u001b[0;32m    186\u001b[0m                     parsed = self.parse_google_json(resultsdict[key],\n\u001b[0;32m    187\u001b[0m                                                     \u001b[0mmeta_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                                                     _esformat)\n\u001b[0m\u001b[0;32m    189\u001b[0m                     \u001b[0mesdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tbonza/code/greenCall/greencall/utils/google.pyc\u001b[0m in \u001b[0;36mparse_google_json\u001b[1;34m(self, valuedict, meta_info, esformat)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m#_esformat['_id'] = int(self.es_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0m_esformat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_source'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_meta_es_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaluedict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m#print('meta wtf: {}'.format(_esformat['_id']))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tbonza/code/greenCall/greencall/utils/google.pyc\u001b[0m in \u001b[0;36mdefine_meta_es_doc\u001b[1;34m(valuedict, meta_info)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mmeta_es_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mmeta_es_doc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'account_holder'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "from greencall.utils.google import GoogleParse\n",
    "from greencall.utils.loadelastic import load_elastic, read_json\n",
    "from greencall.csvclean.inputCsv import read_csv\n",
    "\n",
    "# set elastic search document id to 1 (assumes new index)\n",
    "gp = GoogleParse(es_id = 1)\n",
    "\n",
    "# params \n",
    "resultsdict = read_json(resultspath)\n",
    "accountdict = read_csv(filepath, QUERY_LIMIT)\n",
    "\n",
    "# need to hook up these params\n",
    "load_docs = gp.update_es_doc_id(resultsdict, accountdict, esformat)\n",
    "\n",
    "# bulk load elasticsearch\n",
    "load_elastic(load_docs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
